{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43ec516d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries Imported Successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 1: IMPORT LIBRARIES ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Advanced Machine Learning Libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # For understanding text descriptions\n",
    "from sklearn.metrics.pairwise import cosine_similarity # For finding similarities between cities\n",
    "from sklearn.cluster import KMeans # For grouping cities by budget (Budget vs Luxury)\n",
    "from sklearn.preprocessing import StandardScaler # To scale prices for fair comparison\n",
    "\n",
    "print(\"‚úÖ Libraries Imported Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba1fe2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Loading Data...\n",
      "‚úÖ Data Loaded Successfully!\n",
      "Cities: (534, 8), Hotels: (1102, 13), Food: (1000, 4)\n",
      "Places: (381, 18), Transport: (756, 4)\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 2: LOAD RAW DATASETS ---\n",
    "print(\"üöÄ Loading Data...\")\n",
    "\n",
    "# Load all 5 CSVs uploaded by the user\n",
    "df_city = pd.read_csv('City.csv')\n",
    "df_hotel = pd.read_csv('Hotel.csv')\n",
    "df_food = pd.read_csv('Food.csv')\n",
    "df_places = pd.read_csv('Places.csv')\n",
    "df_transport = pd.read_csv('Transport.csv')\n",
    "\n",
    "print(\"‚úÖ Data Loaded Successfully!\")\n",
    "print(f\"Cities: {df_city.shape}, Hotels: {df_hotel.shape}, Food: {df_food.shape}\")\n",
    "print(f\"Places: {df_places.shape}, Transport: {df_transport.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a98a554c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Starting Data Cleaning Process...\n",
      "‚úÖ Data Cleaning & Deduplication Complete.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 3: DATA CLEANING & STANDARDIZATION ---\n",
    "print(\"üßπ Starting Data Cleaning Process...\")\n",
    "\n",
    "# Helper function to clean string columns (Removes spaces, Title Case)\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.strip().title()\n",
    "    return text\n",
    "\n",
    "# 1. Clean Column Names (Remove spaces like ' City ' -> 'City')\n",
    "for df in [df_city, df_hotel, df_food, df_places, df_transport]:\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "# 2. Clean String Data in Key Columns (Apply the function)\n",
    "df_city['City'] = df_city['City'].apply(clean_text)\n",
    "df_city['State'] = df_city['State'].apply(clean_text)\n",
    "\n",
    "df_hotel['City'] = df_hotel['City'].apply(clean_text)\n",
    "df_hotel['Hotel_Name'] = df_hotel['Hotel_Name'].apply(clean_text)\n",
    "\n",
    "df_food['State'] = df_food['State'].apply(clean_text)\n",
    "\n",
    "df_places['City'] = df_places['City'].apply(clean_text)\n",
    "df_places['State'] = df_places['State'].apply(clean_text)\n",
    "\n",
    "df_transport['From_State'] = df_transport['From_State'].apply(clean_text)\n",
    "df_transport['To_State'] = df_transport['To_State'].apply(clean_text)\n",
    "\n",
    "# 3. Remove Duplicates (Strict Internship Rule)\n",
    "df_city.drop_duplicates(inplace=True)\n",
    "df_hotel.drop_duplicates(inplace=True)\n",
    "df_food.drop_duplicates(inplace=True)\n",
    "df_places.drop_duplicates(inplace=True)\n",
    "df_transport.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"‚úÖ Data Cleaning & Deduplication Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96258ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Missing Values Handled.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 4: HANDLING MISSING VALUES ---\n",
    "\n",
    "# 1. Hotels: Fill missing prices with the median price of that specific city\n",
    "# If the city has no other hotels, use the global median.\n",
    "df_hotel['Hotel_Price'] = df_hotel['Hotel_Price'].fillna(df_hotel['Hotel_Price'].median())\n",
    "\n",
    "# 2. Places: Fill missing ratings with a neutral 4.0\n",
    "df_places['Google review rating'] = df_places['Google review rating'].fillna(4.0)\n",
    "\n",
    "# 3. City: Fill missing descriptions\n",
    "df_city['City_desc'] = df_city['City_desc'].fillna(\"Beautiful destination to visit.\")\n",
    "\n",
    "print(\"‚úÖ Missing Values Handled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training NLP Recommendation Model...\n",
      "‚úÖ Similarity Model Trained.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 5: TRAINING THE RECOMMENDATION ENGINE (CONTENT-BASED) ---\n",
    "print(\"üß† Training NLP Recommendation Model...\")\n",
    "\n",
    "# Initialize TF-IDF Vectorizer (Stop words removes 'the', 'is', 'and')\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and Transform the City Descriptions\n",
    "tfidf_matrix = tfidf.fit_transform(df_city['City_desc'])\n",
    "\n",
    "# Compute Cosine Similarity (The Angle between vectors = Similarity)\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Create a mapping of City Name to Index (for easy lookup later)\n",
    "indices = pd.Series(df_city.index, index=df_city['City']).drop_duplicates()\n",
    "\n",
    "print(\"‚úÖ Similarity Model Trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8956f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Performing K-Means Clustering on Budget...\n",
      "‚úÖ Clustering Complete. Cities categorized by budget.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 6: UNSUPERVISED LEARNING (K-MEANS CLUSTERING) ---\n",
    "print(\"üìä Performing K-Means Clustering on Budget...\")\n",
    "\n",
    "# 1. Aggregate Hotel Prices by City (Average cost to stay in each city)\n",
    "city_prices = df_hotel.groupby('City')['Hotel_Price'].mean().reset_index()\n",
    "\n",
    "# 2. Merge this price info into the main City dataset\n",
    "df_city_ml = pd.merge(df_city, city_prices, on='City', how='left')\n",
    "df_city_ml['Hotel_Price'] = df_city_ml['Hotel_Price'].fillna(df_city_ml['Hotel_Price'].median())\n",
    "\n",
    "# 3. Prepare Data for Clustering\n",
    "X = df_city_ml[['Hotel_Price']]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 4. Apply K-Means (3 Clusters: Low, Medium, High Cost)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df_city_ml['Budget_Cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Label the clusters (0, 1, 2 might be random, so we sort them by price to name them correctly)\n",
    "cluster_mapping = df_city_ml.groupby('Budget_Cluster')['Hotel_Price'].mean().sort_values().index\n",
    "label_map = {cluster_mapping[0]: 'Budget Friendly', cluster_mapping[1]: 'Standard', cluster_mapping[2]: 'Luxury'}\n",
    "df_city_ml['Budget_Category'] = df_city_ml['Budget_Cluster'].map(label_map)\n",
    "\n",
    "print(\"‚úÖ Clustering Complete. Cities categorized by budget.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2e3dba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Raw files loaded.\n",
      "üß† Retraining ML Model...\n",
      "üíæ Saving Clean Files...\n",
      "üéâ FIX COMPLETE. Now run app.py\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Data (Using loose matching for filenames)\n",
    "try:\n",
    "    df_city = pd.read_csv('City.csv')\n",
    "    df_hotel = pd.read_csv('Hotel.csv')\n",
    "    df_food = pd.read_csv('Food.csv')\n",
    "    df_places = pd.read_csv('Places.csv')\n",
    "    print(\"‚úÖ Raw files loaded.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå ERROR: Could not find file. Make sure City.csv, Hotel.csv, etc. are in the folder. Details: {e}\")\n",
    "\n",
    "# 2. Clean Column Names (Strip spaces)\n",
    "for df in [df_city, df_hotel, df_food, df_places]:\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "# 3. Force Numeric Prices (Fixes \"String\" errors)\n",
    "df_hotel['Hotel_Price'] = pd.to_numeric(df_hotel['Hotel_Price'], errors='coerce').fillna(2000)\n",
    "df_food['Price'] = pd.to_numeric(df_food['Price'], errors='coerce').fillna(150)\n",
    "\n",
    "# 4. Standardize Text\n",
    "df_city['City'] = df_city['City'].str.strip().str.title()\n",
    "df_city['State'] = df_city['State'].str.strip().str.title()\n",
    "df_hotel['City'] = df_hotel['City'].str.strip().str.title()\n",
    "df_places['City'] = df_places['City'].str.strip().str.title()\n",
    "\n",
    "# 5. Advanced ML: Generate Similarity Matrix\n",
    "print(\"üß† Retraining ML Model...\")\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "df_city['City_desc'] = df_city['City_desc'].fillna('')\n",
    "tfidf_matrix = tfidf.fit_transform(df_city['City_desc'])\n",
    "similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# 6. Save Clean Files (The Bridge)\n",
    "print(\"üíæ Saving Clean Files...\")\n",
    "df_city.to_csv('clean_city.csv', index=False)\n",
    "df_hotel.to_csv('clean_hotel.csv', index=False)\n",
    "df_food.to_csv('clean_food.csv', index=False)\n",
    "df_places.to_csv('clean_places.csv', index=False)\n",
    "\n",
    "with open('similarity.pkl', 'wb') as f:\n",
    "    pickle.dump(similarity, f)\n",
    "\n",
    "print(\"üéâ FIX COMPLETE. Now run app.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Transport Data Ready.\n"
     ]
    }
   ],
   "source": [
    "# --- RUN THIS TO ADD TRANSPORT DATA ---\n",
    "import pandas as pd\n",
    "try:\n",
    "    df_trans = pd.read_csv('Transport.csv')\n",
    "    df_trans.columns = df_trans.columns.str.strip()\n",
    "    df_trans['From_State'] = df_trans['From_State'].str.strip().str.title()\n",
    "    df_trans['To_State'] = df_trans['To_State'].str.strip().str.title()\n",
    "    df_trans.to_csv('clean_transport.csv', index=False)\n",
    "    print(\"‚úÖ Transport Data Ready.\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Transport.csv not found, proceeding without it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd84272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
